{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987fa025-83a0-45d2-bd9d-ea3f00db966b",
   "metadata": {},
   "source": [
    "**Step 1: Import libraries and load the dataset for preprocessing and analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0b6264a5-b753-47fb-b2ed-9017d8c2e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = \"D:\\\\archive\\\\df_arabica_clean.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009e95a-820b-4a0a-b5a0-ea9708c9a2fd",
   "metadata": {},
   "source": [
    "**Step 2: One-hot encoding categorical features and updating the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6583e720-5c02-4fbe-9209-0c300ca10d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ID Country of Origin                 Farm Name  \\\n",
      "0           0   0          Colombia          Finca El Paraiso   \n",
      "1           1   1            Taiwan  Royal Bean Geisha Estate   \n",
      "2           2   2              Laos        OKLAO coffee farms   \n",
      "3           3   3        Costa Rica                 La Cumbre   \n",
      "4           4   4          Colombia           Finca Santuario   \n",
      "\n",
      "                                Lot Number                           Mill  \\\n",
      "0                               CQU2022015               Finca El Paraiso   \n",
      "1  The 2022 Pacific Rim Coffee Summit,T037       Royal Bean Geisha Estate   \n",
      "2  The 2022 Pacific Rim Coffee Summit,LA01  oklao coffee processing plant   \n",
      "3                               CQU2022017        La Montana Tarrazu MIll   \n",
      "4                               CQU2023002                Finca Santuario   \n",
      "\n",
      "  ICO Number                   Company   Altitude                Region  ...  \\\n",
      "0        NaN      Coffee Quality Union  1700-1930        Piendamo,Cauca  ...   \n",
      "1        NaN  Taiwan Coffee Laboratory       1200                Chiayi  ...   \n",
      "2        NaN  Taiwan Coffee Laboratory       1300  Laos Borofen Plateau  ...   \n",
      "3        NaN      Coffee Quality Union       1900    Los Santos,Tarrazu  ...   \n",
      "4        NaN      Coffee Quality Union  1850-2100         Popayan,Cauca  ...   \n",
      "\n",
      "  Altitude_700  Altitude_750 Altitude_800 Altitude_800-1200 Altitude_850  \\\n",
      "0          0.0           0.0          0.0               0.0          0.0   \n",
      "1          0.0           0.0          0.0               0.0          0.0   \n",
      "2          0.0           0.0          0.0               0.0          0.0   \n",
      "3          0.0           0.0          0.0               0.0          0.0   \n",
      "4          0.0           0.0          0.0               0.0          0.0   \n",
      "\n",
      "  Altitude_850-1100 Altitude_900 Altitude_900-1000 Altitude_950 Altitude_nan  \n",
      "0               0.0          0.0               0.0          0.0          0.0  \n",
      "1               0.0          0.0               0.0          0.0          0.0  \n",
      "2               0.0          0.0               0.0          0.0          0.0  \n",
      "3               0.0          0.0               0.0          0.0          0.0  \n",
      "4               0.0          0.0               0.0          0.0          0.0  \n",
      "\n",
      "[5 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "\n",
    "categorical_features = [\"Country of Origin\", \"Region\", \"Variety\", \"Processing Method\",\"Color\",\"Altitude\"]\n",
    "categorical_features = [col for col in categorical_features if col in data.columns]\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "onehot_encoded = onehot_encoder.fit_transform(data[categorical_features]) # applying one-hot encoding to the categorical features\n",
    "\n",
    "onehot_columns = onehot_encoder.get_feature_names_out(categorical_features)\n",
    "onehot_df = pd.DataFrame(onehot_encoded.toarray(), columns=onehot_columns)   # creates a dataframe with the encoded columns\n",
    "\n",
    "\n",
    "data_encoded = pd.concat([data, onehot_df], axis=1)   # tries to concatenate the encoded columns with the original dataframe\n",
    "\n",
    "\n",
    "\n",
    "print(data_encoded.head())\n",
    "data_encoded.to_csv(\"coffee_quality_encoded.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6cc0e-1943-43ad-81f4-07222573bce4",
   "metadata": {},
   "source": [
    "**Step 3: Applying Standard Scaling to Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8ceb1e84-6694-4434-858c-36b7ab684171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ID Country of Origin                 Farm Name  \\\n",
      "0           0   0          Colombia          Finca El Paraiso   \n",
      "1           1   1            Taiwan  Royal Bean Geisha Estate   \n",
      "2           2   2              Laos        OKLAO coffee farms   \n",
      "3           3   3        Costa Rica                 La Cumbre   \n",
      "4           4   4          Colombia           Finca Santuario   \n",
      "\n",
      "                                Lot Number                           Mill  \\\n",
      "0                               CQU2022015               Finca El Paraiso   \n",
      "1  The 2022 Pacific Rim Coffee Summit,T037       Royal Bean Geisha Estate   \n",
      "2  The 2022 Pacific Rim Coffee Summit,LA01  oklao coffee processing plant   \n",
      "3                               CQU2022017        La Montana Tarrazu MIll   \n",
      "4                               CQU2023002                Finca Santuario   \n",
      "\n",
      "  ICO Number                   Company   Altitude                Region  ...  \\\n",
      "0        NaN      Coffee Quality Union  1700-1930        Piendamo,Cauca  ...   \n",
      "1        NaN  Taiwan Coffee Laboratory       1200                Chiayi  ...   \n",
      "2        NaN  Taiwan Coffee Laboratory       1300  Laos Borofen Plateau  ...   \n",
      "3        NaN      Coffee Quality Union       1900    Los Santos,Tarrazu  ...   \n",
      "4        NaN      Coffee Quality Union  1850-2100         Popayan,Cauca  ...   \n",
      "\n",
      "  Altitude_700  Altitude_750 Altitude_800 Altitude_800-1200 Altitude_850  \\\n",
      "0          0.0           0.0          0.0               0.0          0.0   \n",
      "1          0.0           0.0          0.0               0.0          0.0   \n",
      "2          0.0           0.0          0.0               0.0          0.0   \n",
      "3          0.0           0.0          0.0               0.0          0.0   \n",
      "4          0.0           0.0          0.0               0.0          0.0   \n",
      "\n",
      "  Altitude_850-1100 Altitude_900 Altitude_900-1000 Altitude_950 Altitude_nan  \n",
      "0               0.0          0.0               0.0          0.0          0.0  \n",
      "1               0.0          0.0               0.0          0.0          0.0  \n",
      "2               0.0          0.0               0.0          0.0          0.0  \n",
      "3               0.0          0.0               0.0          0.0          0.0  \n",
      "4               0.0          0.0               0.0          0.0          0.0  \n",
      "\n",
      "[5 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_encoded = pd.read_csv(\"coffee_quality_encoded.csv\")\n",
    "numeric_features = [\"Aroma\", \"Flavor\", \"Aftertaste\", \"Acidity\", \"Body\", \"Balance\", \"Sweetness\", \"Moisture Percentage\",\"Total Cup Points\",\"Overall\"]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numeric_features] = scaler.fit_transform(data_encoded[numeric_features])   # applying scaling to the numeric features\n",
    "\n",
    "\n",
    "print(data_encoded.head())\n",
    "data_encoded.to_csv(\"coffee_quality_scaled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce5d54-85e8-43bf-868d-7689bfad3234",
   "metadata": {},
   "source": [
    "**Step 4: Computing Mutual Information Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "019b2105-f257-4255-902f-b2b5c2023ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>MI Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>3.238321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>3.234456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overall</td>\n",
       "      <td>1.416480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balance</td>\n",
       "      <td>1.133940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aftertaste</td>\n",
       "      <td>1.114341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flavor</td>\n",
       "      <td>1.037029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acidity</td>\n",
       "      <td>0.823133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aroma</td>\n",
       "      <td>0.785720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Body</td>\n",
       "      <td>0.631359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Moisture Percentage</td>\n",
       "      <td>0.132724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  MI Score\n",
       "1                    ID  3.238321\n",
       "0            Unnamed: 0  3.234456\n",
       "12              Overall  1.416480\n",
       "8               Balance  1.133940\n",
       "5            Aftertaste  1.114341\n",
       "4                Flavor  1.037029\n",
       "6               Acidity  0.823133\n",
       "3                 Aroma  0.785720\n",
       "7                  Body  0.631359\n",
       "14  Moisture Percentage  0.132724"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "selected_features = [\n",
    "    'Unnamed: 0', 'ID', 'Number of Bags', 'Aroma', 'Flavor', 'Aftertaste',\n",
    "    'Acidity', 'Body', 'Balance', 'Uniformity', 'Clean Cup', 'Sweetness',\n",
    "    'Overall', 'Defects', 'Total Cup Points', 'Moisture Percentage',\n",
    "    'Category One Defects', 'Quakers', 'Category Two Defects'\n",
    "]\n",
    "df_selected = df[selected_features]\n",
    "# Compute Mutual Information Scores for All Features\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Compute mutual information scores for all features with the target variable 'Total Cup Points'\n",
    "mi_scores = mutual_info_regression(df_selected.drop(columns=['Total Cup Points']), df_selected['Total Cup Points'])\n",
    "\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'Feature': df_selected.drop(columns=['Total Cup Points']).columns,\n",
    "    'MI Score': mi_scores\n",
    "}).sort_values(by='MI Score', ascending=False)\n",
    "\n",
    "# Display the top features based on mutual information scores\n",
    "mi_scores_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b87e61-5dbb-4503-a2af-82729a627e87",
   "metadata": {},
   "source": [
    "**Step 5: Feature Selection Based on Mutual Information Score & Mapping Continents, Categorizing Processing Methods and Colors, Classifying Altitudes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f817f9d6-5540-41d5-9505-91a6392d299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully preprocessed Data.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"coffee_quality_scaled.csv\")\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    'ID', 'Country of Origin', 'Processing Method', \n",
    "    'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance', \n",
    "    'Overall', 'Color', 'Altitude', 'Total Cup Points'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df_filtered = df[columns_to_keep].copy()\n",
    "\n",
    "# Map countries to their respective continents\n",
    "continent_mapping = {\n",
    "    'Colombia': 'America', 'Taiwan': 'Asia', 'Laos': 'Asia', 'Costa Rica': 'America', \n",
    "    'Guatemala': 'America', 'Tanzania, United Republic Of': 'Africa', 'Ethiopia': 'Africa', \n",
    "    'Thailand': 'Asia', 'Brazil': 'America', 'United States (Hawaii)': 'America', 'Kenya': 'Africa', \n",
    "    'Uganda': 'Africa', 'Indonesia': 'Asia', 'Peru': 'America', 'Panama': 'America', \n",
    "    'Nicaragua': 'America', 'Vietnam': 'Asia', 'Honduras': 'America', 'El Salvador': 'America', \n",
    "    'Madagascar': 'Africa', 'Mexico': 'America', 'Myanmar': 'Asia'\n",
    "}\n",
    "\n",
    "# Map the 'Continent of Origin' column based on 'Country of Origin'\n",
    "df_filtered['Continent of Origin'] = df_filtered['Country of Origin'].map(continent_mapping).fillna('Unknown')\n",
    "\n",
    "# Define a function to categorize processing methods\n",
    "def categorize_processing_method(method):\n",
    "    method = str(method).strip().lower()\n",
    "    if method in ['washed / wet', 'natural / dry', 'pulped natural / honey']:\n",
    "        return method.title()\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_filtered['Processing Method'] = df_filtered['Processing Method'].apply(categorize_processing_method)\n",
    "\n",
    "# Define a function to categorize colors into four groups\n",
    "def final_categorize_color(color):\n",
    "    if pd.isna(color):\n",
    "        return 'Multicolored'\n",
    "    color_lower = color.lower()\n",
    "    if 'greenish' in color_lower and 'yellow' not in color_lower and 'brown' not in color_lower:\n",
    "        return 'Green'\n",
    "    elif 'yellowish' in color_lower and 'green' not in color_lower and 'brown' not in color_lower:\n",
    "        return 'Yellow'\n",
    "    elif 'brownish' in color_lower and 'green' not in color_lower and 'yellow' not in color_lower:\n",
    "        return 'Brown'\n",
    "    else:\n",
    "        # All other cases, including combinations, will be categorized as 'Multicolored'\n",
    "        return 'Multicolored'\n",
    "df_filtered['Color'] = df_filtered['Color'].apply(final_categorize_color)\n",
    "\n",
    "# Define a function to classify altitudes into specific ranges\n",
    "def classify_altitude(altitude):\n",
    "    try:\n",
    "        if '-' in str(altitude):\n",
    "            # Take the average of the range\n",
    "            alt_values = [float(x) for x in altitude.split('-')]\n",
    "            avg_altitude = np.mean(alt_values)\n",
    "        else:\n",
    "            avg_altitude = float(altitude)\n",
    "        \n",
    "        # Classify based on the given ranges\n",
    "        if avg_altitude < 800:\n",
    "            return 'Low Altitude (<800m)'\n",
    "        elif 800 <= avg_altitude < 1200:\n",
    "            return 'Medium-Low Altitude (800-1200m)'\n",
    "        elif 1200 <= avg_altitude < 1600:\n",
    "            return 'Medium Altitude (1200-1600m)'\n",
    "        elif 1600 <= avg_altitude <= 2000:\n",
    "            return 'High Altitude (1600-2000m)'\n",
    "        else:\n",
    "            return 'Very High Altitude (>2000m)'\n",
    "    except (ValueError, TypeError):\n",
    "        return 'Unknown'\n",
    "df_filtered['Altitude'] = df_filtered['Altitude'].apply(classify_altitude)\n",
    "\n",
    "# Export the filtered DataFrame to a CSV file\n",
    "df_filtered.to_csv(\"preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"Sucessfully preprocessed Data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b8f8e-3f00-4be6-854f-343c1547c9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a21fe9-7d07-4ce8-9267-f6dec259f691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
